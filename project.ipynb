{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639f658d-9088-4e3a-a249-43020081d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "print(\"Imports OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9324a165-0863-4a9e-8674-1f9b2c792693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# yaha apna actual dataset ka path daalo\n",
    "DATASET_PATH = r\"C:\\Users\\sahil\\music-genre-classifier\\data\\genres_original\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5b4317-2f41-4e49-8cf7-7b85312a5c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: C:\\Users\\sahil\\music-genre-classifier\n",
      "Files: ['.ipynb_checkpoints', 'archive (1)', 'archive (1).zip', 'data.json', 'database', 'feature_extractor.py', 'genres_original', 'models', 'project.ipynb', 'requirements.txt', 'Untitled.ipynb', 'Untitled3 (1).ipynb', 'Untitled3.ipynb', 'venv']\n",
      "Database: ['.ipynb_checkpoints', 'classical_01.wav', 'classical_02.wav', 'classical_03.wav', 'hiphop_01.wav', 'song1.wav']\n"
     ]
    }
   ],
   "source": [
    "print(\"Working Directory:\", os.getcwd())\n",
    "print(\"Files:\", os.listdir(\".\"))\n",
    "print(\"Database:\", os.listdir(\"database\") if os.path.exists(\"database\") else \"No database folder found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defd8c0b-c15c-4a17-9834-980b7eb006b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path, sr=22050, n_mfcc=20):\n",
    "    try:\n",
    "        y, sr = librosa.load(path, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfcc.T, axis=0)\n",
    "    except Exception as e:\n",
    "        print(\"Error loading:\", path, e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09814efc-0d2b-4609-9a0e-e309de98f3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio files found: ['classical_01.wav', 'classical_02.wav', 'classical_03.wav', 'hiphop_01.wav', 'song1.wav']\n",
      "Test file: database\\classical_01.wav\n",
      "Feature vector shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "audio_files = sorted([f for f in os.listdir(\"database\") if f.lower().endswith((\".wav\", \".mp3\"))])\n",
    "\n",
    "print(\"Audio files found:\", audio_files)\n",
    "\n",
    "if len(audio_files) == 0:\n",
    "    raise SystemExit(\"No audio files found in database/. Please upload WAV files like rock_01.wav\")\n",
    "\n",
    "test_file = os.path.join(\"database\", audio_files[0])\n",
    "feat = extract_features(test_file)\n",
    "\n",
    "print(\"Test file:\", test_file)\n",
    "print(\"Feature vector shape:\", feat.shape if feat is not None else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5894b1-0a4a-4dfb-a39e-8aeaa625c9fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m label = fname.split(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]   \u001b[38;5;66;03m# genre before underscore\u001b[39;00m\n\u001b[32m     31\u001b[39m path = os.path.join(\u001b[33m\"\u001b[39m\u001b[33mdatabase\u001b[39m\u001b[33m\"\u001b[39m, fname)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m f = \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     34\u001b[39m     X.append(f)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     12\u001b[39m y, sr = librosa.load(file_path, sr=\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# sr=None to keep original sample rate\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Extract MFCCs (13 coefficients by default, can adjust)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m mfccs = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m13\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Flatten the MFCCs into a 1D array for easier use in ML models\u001b[39;00m\n\u001b[32m     18\u001b[39m features = mfccs.flatten()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\music-genre-classifier\\venv\\Lib\\site-packages\\librosa\\feature\\spectral.py:1993\u001b[39m, in \u001b[36mmfcc\u001b[39m\u001b[34m(y, sr, S, n_mfcc, dct_type, norm, lifter, mel_norm, **kwargs)\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[32m   1847\u001b[39m \n\u001b[32m   1848\u001b[39m \u001b[33;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1989\u001b[39m \u001b[33;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1992\u001b[39m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m     S = power_to_db(\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1995\u001b[39m fft = get_fftlib()\n\u001b[32m   1996\u001b[39m M: np.ndarray = fft.dct(S, axis=-\u001b[32m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m=dct_type, norm=norm)[\n\u001b[32m   1997\u001b[39m     ..., :n_mfcc, :\n\u001b[32m   1998\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\music-genre-classifier\\venv\\Lib\\site-packages\\librosa\\feature\\spectral.py:2148\u001b[39m, in \u001b[36mmelspectrogram\u001b[39m\u001b[34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[39m\n\u001b[32m   2135\u001b[39m S, n_fft = _spectrogram(\n\u001b[32m   2136\u001b[39m     y=y,\n\u001b[32m   2137\u001b[39m     S=S,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2144\u001b[39m     pad_mode=pad_mode,\n\u001b[32m   2145\u001b[39m )\n\u001b[32m   2147\u001b[39m \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2148\u001b[39m mel_basis = \u001b[43mfilters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2150\u001b[39m melspec: np.ndarray = np.einsum(\u001b[33m\"\u001b[39m\u001b[33m...ft,mf->...mt\u001b[39m\u001b[33m\"\u001b[39m, S, mel_basis, optimize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m melspec\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\music-genre-classifier\\venv\\Lib\\site-packages\\librosa\\filters.py:231\u001b[39m, in \u001b[36mmel\u001b[39m\u001b[34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[39m\n\u001b[32m    228\u001b[39m mel_f = mel_frequencies(n_mels + \u001b[32m2\u001b[39m, fmin=fmin, fmax=fmax, htk=htk)\n\u001b[32m    230\u001b[39m fdiff = np.diff(mel_f)\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m ramps = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubtract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mouter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfftfreqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_mels):\n\u001b[32m    234\u001b[39m     \u001b[38;5;66;03m# lower and upper slopes for all bins\u001b[39;00m\n\u001b[32m    235\u001b[39m     lower = -ramps[i] / fdiff[i]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa  # For audio feature extraction\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Extract MFCC features from an audio file.\n",
    "    Returns a flattened array of features or None if extraction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the audio file (librosa handles .wav and .mp3)\n",
    "        y, sr = librosa.load(file_path, sr=None)  # sr=None to keep original sample rate\n",
    "        \n",
    "        # Extract MFCCs (13 coefficients by default, can adjust)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        \n",
    "        # Flatten the MFCCs into a 1D array for easier use in ML models\n",
    "        features = mfccs.flatten()\n",
    "        \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Your original code continues here\n",
    "X, y = [], []\n",
    "\n",
    "for fname in sorted(os.listdir(\"database\")):\n",
    "    if fname.lower().endswith((\".wav\", \".mp3\")):\n",
    "        label = fname.split(\"_\")[0]   # genre before underscore\n",
    "        path = os.path.join(\"database\", fname)\n",
    "        f = extract_features(path)\n",
    "        if f is not None:\n",
    "            X.append(f)\n",
    "            y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Unique labels:\", np.unique(y, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb9644-49cb-49c4-84b1-3bf2455d2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# yeh path wahi hai jahan tumhara dataset hai\n",
    "BASE_DIR = r\"archive (1)\\Data\\genres_original\"\n",
    "\n",
    "# sab genre folders ka naam nikalna\n",
    "genres = [d for d in os.listdir(BASE_DIR) \n",
    "          if os.path.isdir(os.path.join(BASE_DIR, d))]\n",
    "\n",
    "print(\"Genres mil gaye:\\n\", genres)\n",
    "print(\"\\nHar genre me kitni .wav files hain:\\n\")\n",
    "\n",
    "total_files = 0\n",
    "\n",
    "for genre in sorted(genres):\n",
    "    folder_path = os.path.join(BASE_DIR, genre)\n",
    "    \n",
    "    # sirf .wav files count karna\n",
    "    files = [f for f in os.listdir(folder_path) \n",
    "             if f.lower().endswith(\".wav\")]\n",
    "    \n",
    "    count = len(files)\n",
    "    total_files += count\n",
    "    \n",
    "    print(f\"{genre:10s} -> {count} files\")\n",
    "\n",
    "print(\"\\nTotal .wav files:\", total_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442de9ac-6185-4965-abff-3970b1cad562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system,\n",
    "# primarily for file and directory operations.\n",
    "import os\n",
    "\n",
    "# IMPORTANT: yahan hum wahi path denge jahan tumhara 'genres_original' folder hai\n",
    "# Tumhare case me: archive (1)\\Data\\genres_original\n",
    "DATASET_PATH = r\"archive (1)\\Data\\genres_original\"\n",
    "\n",
    "# A basic sanity check to ensure the dataset directory actually exists\n",
    "# before we try to loop through it. This prevents errors if the script\n",
    "# is run in the wrong place or if the data hasn't been unzipped.\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"Error: Dataset path '{DATASET_PATH}' not found.\")\n",
    "    print(\"Please ensure you are running this script from the 'music-genre-classifier' folder.\")\n",
    "else:\n",
    "    print(\"Dataset directory found. Counting files in each genre folder...\")\n",
    "    print(\"-\" * 40)  # A separator for cleaner output\n",
    "\n",
    "    # We use os.listdir() to get a list of all items inside the DATASET_PATH.\n",
    "    # These items should be our 10 genre folders ('blues', 'classical', etc.).\n",
    "    # We use sorted() to ensure the output is always in alphabetical order,\n",
    "    # which is just a nice-to-have for readability.\n",
    "    for genre_folder in sorted(os.listdir(DATASET_PATH)):\n",
    "\n",
    "        # We construct the full path to the genre folder.\n",
    "        genre_path = os.path.join(DATASET_PATH, genre_folder)\n",
    "\n",
    "        # Ensure the item we're looking at is a directory (i.e. a folder).\n",
    "        if os.path.isdir(genre_path):\n",
    "\n",
    "            # List all files inside this genre folder\n",
    "            files_in_genre = os.listdir(genre_path)\n",
    "\n",
    "            # Count how many files there are\n",
    "            number_of_files = len(files_in_genre)\n",
    "\n",
    "            # Print the result in a nicely formatted way.\n",
    "            print(f\"Genre: {genre_folder.ljust(12)} | File Count: {number_of_files}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Verification complete. Please check that each genre has 100 files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f5bc9-d9ec-41cc-94dd-2cf407f1d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os          # To interact with the file system (navigate paths, list files)\n",
    "import json        # To save our final data in a structured JSON format (we'll later switch to CSV)\n",
    "import librosa     # The core library for audio analysis and feature extraction\n",
    "\n",
    "DATASET_PATH = r\"archive (1)\\Data\\genres_original\"\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "data = {\n",
    "    \"mapping\": [],\n",
    "    \"labels\": [],\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "print(\"Starting feature extraction...\")\n",
    "print(\"Feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4bdefd-a9d3-4bb2-ba10-ed70d103c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "# ---- AUDIO SETTINGS (important constants) ----\n",
    "\n",
    "# 1) Sample rate: 22050 Hz (librosa ka default, audio ML me bohot common)\n",
    "SAMPLE_RATE = 22050  # samples per second\n",
    "\n",
    "# 2) Har track ki duration (GTZAN me har song ~30 seconds ka hai)\n",
    "TRACK_DURATION = 30  # seconds\n",
    "\n",
    "# 3) Har track ko kitne parts/segments me todna hai\n",
    "#    10 ka matlab: 30 sec / 10 = 3 sec per segment\n",
    "NUM_SEGMENTS = 10\n",
    "\n",
    "# 4) Ek poore track me total samples kitne honge:\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION  # 22050 * 30 = 661500\n",
    "\n",
    "# Tumhara dataset path (jahan genres_original hai)\n",
    "DATASET_PATH = r\"archive (1)\\Data\\genres_original\"\n",
    "\n",
    "# Processed features ko future me JSON file me save karne ke liye\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "print(\"Audio settings set ho gaye ✅\")\n",
    "print(\"SAMPLE_RATE:\", SAMPLE_RATE)\n",
    "print(\"TRACK_DURATION:\", TRACK_DURATION, \"seconds\")\n",
    "print(\"NUM_SEGMENTS:\", NUM_SEGMENTS)\n",
    "print(\"SAMPLES_PER_TRACK:\", SAMPLES_PER_TRACK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16921c4-068a-4838-9dfc-576f0bc13172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os          # file/folder ke saath kaam ke liye\n",
    "import json        # baad me data ko JSON/CSV ke liye\n",
    "import librosa     # audio processing ke liye\n",
    "\n",
    "# Tumhara actual dataset path:\n",
    "DATASET_PATH = r\"archive (1)\\Data\\genres_original\"\n",
    "\n",
    "# Processed data save karne ke liye:\n",
    "JSON_PATH = \"data.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1356bc7-7374-4569-b000-a96ef29a306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- AUDIO PROCESSING CONSTANTS ----\n",
    "\n",
    "# 1) Kitne Hz pe audio sample karna hai\n",
    "SAMPLE_RATE = 22050  # librosa ka standard sample rate\n",
    "\n",
    "# 2) Har GTZAN track ki length (seconds me)\n",
    "TRACK_DURATION_SECONDS = 30  # GTZAN me sab tracks ~30 sec ke hain\n",
    "\n",
    "# 3) Har track ko kitne parts me todna hai\n",
    "NUM_SEGMENTS = 10  # 30 sec / 10 = 3 sec per segment\n",
    "\n",
    "# 4) Ek poore 30 sec track me total samples kitne honge\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n",
    "\n",
    "print(\"Constants set ho gaye ✅\")\n",
    "print(\"SAMPLE_RATE:\", SAMPLE_RATE)\n",
    "print(\"TRACK_DURATION_SECONDS:\", TRACK_DURATION_SECONDS)\n",
    "print(\"NUM_SEGMENTS:\", NUM_SEGMENTS)\n",
    "print(\"SAMPLES_PER_TRACK:\", SAMPLES_PER_TRACK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e01182-be85-4ff2-bcc4-04cec97feff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "DATASET_PATH = r\"archive (1)\\Data\\genres_original\"\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "# Define constants for audio processing\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION_SECONDS = 30\n",
    "NUM_SEGMENTS = 10\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n",
    "\n",
    "def process_dataset(dataset_path, json_path):\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"features\": []\n",
    "    }\n",
    "\n",
    "    print(\"Starting feature extraction...\")\n",
    "    # yahan baad me main loop aayega\n",
    "    print(\"Feature extraction complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527c67c-cd2a-454d-b80e-3b38e2198b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os      # Folders/files ke saath kaam karne ke liye\n",
    "import json    # Data ko JSON file me save karne ke liye\n",
    "import librosa # Audio files ko read & process karne ke liye\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fb5ddb-95c5-48a6-a5c5-8ea223dbde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to GTZAN dataset (jahan tumhare songs hai)\n",
    "DATASET_PATH = \"genres_original\"\n",
    "\n",
    "# Jahan output (features) save honge\n",
    "JSON_PATH = \"data.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709e96b-46fc-43c0-801d-cb8fcf6e9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for audio processing\n",
    "\n",
    "# 1) Kitne samples per second lene hain? (Jaise video me frames per second)\n",
    "SAMPLE_RATE = 22050  # librosa ka default rate\n",
    "\n",
    "# 2) Har song ki length (GTZAN dataset me har gaana 30 sec ka hai)\n",
    "TRACK_DURATION_SECONDS = 30\n",
    "\n",
    "# 3) Humein ek poore gaane ko kitne parts me todna hai?\n",
    "NUM_SEGMENTS = 10  # matlab: 30 sec / 10 = har part 3 sec ka\n",
    "\n",
    "# 4) Total kitne samples honge poore 30 sec me?\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e6936-1221-4e65-82fe-a595d3d5fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, json_path):\n",
    "    \"\"\"\n",
    "    Ye function baad me:\n",
    "    - dataset ke har folder (genre) me jaayega\n",
    "    - har audio file padega\n",
    "    - features nikalega\n",
    "    - sab JSON file me save karega\n",
    "\n",
    "    Abhi ke liye hum sirf structure bana rahe hain.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data store karne ke liye empty dictionary\n",
    "    data = {\n",
    "        \"mapping\": [],  # genre names (e.g., \"blues\", \"classical\", ...)\n",
    "        \"labels\": [],   # har sample ka numeric label (0,1,2,...)\n",
    "        \"features\": []  # har sample ke features (numbers)\n",
    "    }\n",
    "\n",
    "    print(\"Starting feature extraction...\")\n",
    "\n",
    "    # Yahan baad me hum loops & feature extraction ka code likhenge\n",
    "\n",
    "    print(\"Feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55281d0a-5da8-4ed6-9070-d929b671e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f10073-4742-47a3-9b2a-0ae5b91fa030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc3be3-dfc5-49a8-af83-67a251a47d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182e52b-4bab-4492-9e9f-aec276be5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"archive (1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c64bd-fc0e-443f-8942-2992e797e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b1bc2-40ff-4273-985d-91c3a02d5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d41a3-b327-4612-9e0d-4d92319c7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab907c1-124b-435b-9927-aed39076640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"genres_original\"\n",
    "JSON_PATH = \"data.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c801a-8372-4926-877b-be4391607108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, json_path):\n",
    "    \"\"\"\n",
    "    The main function to extract features from the dataset and save them to a JSON file.\n",
    "\n",
    "    This function will iterate through all genre sub-folders in the dataset, process\n",
    "    each audio file, and extract relevant features.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): The path to the root of the dataset directory.\n",
    "        json_path (str): The path to the file where the extracted data will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary to store all our data\n",
    "    data = {\n",
    "        \"mapping\": [],      # List of genre names, e.g., [\"blues\", \"classical\", ...]\n",
    "        \"labels\": [],       # The corresponding genre label (as an integer) for each track/segment\n",
    "        \"features\": []      # The extracted features for each track/segment\n",
    "    }\n",
    "\n",
    "    print(\"Starting feature extraction...\")\n",
    "\n",
    "    # --- Genre-level loop ---\n",
    "    # Iterate through all the genre folders in the dataset path\n",
    "    for i, genre_folder in enumerate(sorted(os.listdir(dataset_path))):\n",
    "\n",
    "        # Full path to this genre folder\n",
    "        genre_path = os.path.join(dataset_path, genre_folder)\n",
    "\n",
    "        # Sirf folders process karo (hidden files skip ho jayenge)\n",
    "        if os.path.isdir(genre_path):\n",
    "            \n",
    "            # Genre name save karo mapping list me\n",
    "            data[\"mapping\"].append(genre_folder)\n",
    "            \n",
    "            print(f\"\\nProcessing genre: {genre_folder}\")\n",
    "            # Next task me yahi andar .wav files pe loop likhenge\n",
    "\n",
    "    # --- Loop end ---\n",
    "\n",
    "    # Baad me yahin JSON save karenge\n",
    "    # with open(json_path, \"w\") as fp:\n",
    "    #     json.dump(data, fp, indent=4)\n",
    "    \n",
    "    print(\"\\nFeature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe38b96-be3c-4b57-8d71-c572c39f92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87607b-1755-414f-bc10-46a73e3de2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, json_path):\n",
    "    \"\"\"\n",
    "    The main function to extract features from the dataset and save them to a JSON file.\n",
    "\n",
    "    This function will iterate through all genre sub-folders in the dataset, process\n",
    "    each audio file, and extract relevant features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary to store all our data\n",
    "    data = {\n",
    "        \"mapping\": [],      # List of genre names, e.g., [\"blues\", \"classical\", ...]\n",
    "        \"labels\": [],       # The corresponding genre label (as an integer) for each track/segment\n",
    "        \"features\": []      # The extracted features for each track/segment\n",
    "    }\n",
    "\n",
    "    print(\"Starting feature extraction...\")\n",
    "\n",
    "    # OUTER LOOP: har genre folder ke liye\n",
    "    for i, genre_folder in enumerate(sorted(os.listdir(dataset_path))):\n",
    "        genre_path = os.path.join(dataset_path, genre_folder)\n",
    "\n",
    "        # Sirf folders process karne hain\n",
    "        if os.path.isdir(genre_path):\n",
    "            data[\"mapping\"].append(genre_folder)\n",
    "            print(f\"\\nProcessing genre: {genre_folder}\")\n",
    "\n",
    "            # INNER LOOP: is genre ke andar jitni bhi files hain unpe loop\n",
    "            for filename in sorted(os.listdir(genre_path)):\n",
    "\n",
    "                # Sirf .wav files hi chahiye\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    # full path banao: genres_original/genre/filename.wav\n",
    "                    file_path = os.path.join(genre_path, filename)\n",
    "\n",
    "                    # Debug ke liye chaaho to yeh line uncomment karo:\n",
    "                    # print(f\"  Processing file: {file_path}\")\n",
    "\n",
    "    print(\"\\nFeature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76627773-805e-40a8-92a3-38579baae3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "DATASET_PATH = \"genres_original\"\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION_SECONDS = 30\n",
    "NUM_SEGMENTS = 10\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14168283-d4e0-4b84-8ed4-66fe36b74a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df71f1f-1641-47ed-906a-104935a2b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC configuration\n",
    "NUM_MFCC = 13       # how many MFCCs we want\n",
    "N_FFT = 2048        # FFT window size\n",
    "HOP_LENGTH = 512    # number of samples between each frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0e090-b6ba-4529-92cf-2c165fff89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = \"genres_original\"   # make sure this folder exists in your project\n",
    "JSON_PATH = \"data.json\"            # output file\n",
    "\n",
    "# Audio processing constants\n",
    "SAMPLE_RATE = 22050               # librosa default\n",
    "TRACK_DURATION_SECONDS = 30       # GTZAN tracks ~30 sec\n",
    "NUM_SEGMENTS = 10                 # split each track into 10 segments\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n",
    "\n",
    "# MFCC configuration\n",
    "NUM_MFCC = 13        # number of MFCCs\n",
    "N_FFT = 2048         # window size for FFT\n",
    "HOP_LENGTH = 512     # hop length between frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cddb59-cd33-493f-bff1-20b8d32013a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, json_path):\n",
    "    \"\"\"\n",
    "    Extracts MFCC features from each audio file in the dataset and saves them to a JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"mapping\": [],   # genre names\n",
    "        \"labels\": [],    # numerical labels (0,1,2,...)\n",
    "        \"features\": []   # MFCC features for each segment\n",
    "    }\n",
    "\n",
    "    print(\"Starting feature extraction...\")\n",
    "\n",
    "    # loop over all genre folders\n",
    "    for i, genre_folder in enumerate(sorted(os.listdir(dataset_path))):\n",
    "        genre_path = os.path.join(dataset_path, genre_folder)\n",
    "\n",
    "        # only process directories\n",
    "        if os.path.isdir(genre_path):\n",
    "            data[\"mapping\"].append(genre_folder)\n",
    "            print(f\"\\nProcessing genre: {genre_folder} (label {i})\")\n",
    "\n",
    "            # loop over all files in this genre folder\n",
    "            for filename in sorted(os.listdir(genre_path)):\n",
    "\n",
    "                # only process .wav files\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(genre_path, filename)\n",
    "\n",
    "                    # 1) Try loading file safely\n",
    "                    try:\n",
    "                        signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                    except Exception:\n",
    "                        print(f\"  Skipping corrupted file: {file_path}\")\n",
    "                        continue\n",
    "\n",
    "                    # 2) Compute how many samples per segment\n",
    "                    samples_per_segment = int(SAMPLES_PER_TRACK / NUM_SEGMENTS)\n",
    "\n",
    "                    # 3) Loop over segments in this file\n",
    "                    for s in range(NUM_SEGMENTS):\n",
    "                        start_sample = samples_per_segment * s\n",
    "                        end_sample = start_sample + samples_per_segment\n",
    "\n",
    "                        # safety check\n",
    "                        if end_sample <= len(signal):\n",
    "\n",
    "                            # 4) extract MFCC for this segment\n",
    "                            mfcc_features = librosa.feature.mfcc(\n",
    "                                y=signal[start_sample:end_sample],\n",
    "                                sr=sr,\n",
    "                                n_fft=N_FFT,\n",
    "                                hop_length=HOP_LENGTH,\n",
    "                                n_mfcc=NUM_MFCC\n",
    "                            )\n",
    "\n",
    "                            # 5) compress along time axis\n",
    "                            mfcc_mean = mfcc_features.T.mean(axis=0)\n",
    "\n",
    "                            # 6) store data\n",
    "                            data[\"features\"].append(mfcc_mean.tolist())\n",
    "                            data[\"labels\"].append(i)\n",
    "\n",
    "    # 7) save everything to JSON\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "    print(\"\\nFeature extraction complete and saved to\", json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7945427f-51cd-478b-bade-a0ff7544b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a0a2d-98f2-4ecb-8070-b62f2e35acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, json_path):\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"features\": []\n",
    "    }\n",
    "\n",
    "    print(\"Starting feature extraction...\")\n",
    "\n",
    "    for i, genre_folder in enumerate(sorted(os.listdir(dataset_path))):\n",
    "        genre_path = os.path.join(dataset_path, genre_folder)\n",
    "\n",
    "        if os.path.isdir(genre_path):\n",
    "            data[\"mapping\"].append(genre_folder)\n",
    "            print(f\"\\nProcessing genre: {genre_folder}\")\n",
    "\n",
    "            for filename in sorted(os.listdir(genre_path)):\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(genre_path, filename)\n",
    "\n",
    "                    # --- NEW: load with librosa + try/except ---\n",
    "                    try:\n",
    "                        signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                        # Optional: debug print\n",
    "                        # print(f\"  Loaded file: {file_path}, signal length = {len(signal)}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading file {file_path}: {e}\")\n",
    "                        continue\n",
    "                    # --- END BLOCK ---\n",
    "\n",
    "    print(\"\\nFeature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bab301-1d62-4a5f-af7d-8967e69b095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec07ef-7dfd-4d01-b09f-b345ef7eee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = \"genres_original\"\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "# Audio processing constants\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION_SECONDS = 30\n",
    "NUM_SEGMENTS = 10\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa119493-5127-4205-914b-57f9dde0ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, json_path):\n",
    "    \"\"\"\n",
    "    The main function to walk through the dataset, load audio files,\n",
    "    and segment each track into smaller chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"features\": []\n",
    "    }\n",
    "\n",
    "    print(\"Starting feature extraction...\")\n",
    "\n",
    "    # loop over genres\n",
    "    for i, genre_folder in enumerate(sorted(os.listdir(dataset_path))):\n",
    "        genre_path = os.path.join(dataset_path, genre_folder)\n",
    "\n",
    "        if os.path.isdir(genre_path):\n",
    "            data[\"mapping\"].append(genre_folder)\n",
    "            print(f\"\\nProcessing genre: {genre_folder}\")\n",
    "\n",
    "            # loop over files in this genre\n",
    "            for filename in sorted(os.listdir(genre_path)):\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(genre_path, filename)\n",
    "\n",
    "                    try:\n",
    "                        # 1) Load the audio file\n",
    "                        signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                        # 2) Check if signal is long enough\n",
    "                        if len(signal) >= SAMPLES_PER_TRACK:\n",
    "\n",
    "                            # 3) Calculate samples per segment\n",
    "                            num_samples_per_segment = int(SAMPLES_PER_TRACK / NUM_SEGMENTS)\n",
    "\n",
    "                            # 4) Loop over all segments\n",
    "                            for s in range(NUM_SEGMENTS):\n",
    "                                start_sample = s * num_samples_per_segment\n",
    "                                end_sample = start_sample + num_samples_per_segment\n",
    "\n",
    "                                # 5) Extract the segment\n",
    "                                segment = signal[start_sample:end_sample]\n",
    "\n",
    "                                # Debug (optional): dekhna hai kya ho raha hai\n",
    "                                # print(f\"  Segment {s+1}/{NUM_SEGMENTS} from file {filename}, length: {len(segment)}\")\n",
    "\n",
    "                                # Next tasks me yahin se MFCC etc. nikalenge\n",
    "                        else:\n",
    "                            print(f\"  Skipping short file: {file_path} (len={len(signal)})\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading file {file_path}: {e}\")\n",
    "                        continue\n",
    "\n",
    "    print(\"\\nFeature extraction complete (segmentation step done).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd2ebb-865c-40b1-acf3-46131334817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78026404-bebe-4bcf-bc91-a47024e25756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np  # NEW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e457fd-68cb-4996-8f40-56f1a0ee3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset (GTZAN)\n",
    "DATASET_PATH = \"genres_original\"\n",
    "\n",
    "# Path to save processed features\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "# Audio settings\n",
    "SAMPLE_RATE = 22050          # 22.05 kHz\n",
    "TRACK_DURATION_SECONDS = 30  # Har track 30 sec\n",
    "NUM_SEGMENTS = 10            # 10 segments -> 3 sec each\n",
    "\n",
    "# MFCC settings\n",
    "NUM_MFCC = 13       # 13 coefficients\n",
    "N_FFT = 2048        # FFT window size\n",
    "HOP_LENGTH = 512    # Hop length\n",
    "\n",
    "# Total samples per track\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb163b-e939-4ca1-a9c0-7e2b522242a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_path, json_path):\n",
    "    # Is dict me sab features store honge\n",
    "    data = {\n",
    "        \"mapping\": [],  # index -> genre name\n",
    "        \"labels\": [],   # y (genre label as number)\n",
    "        \"mfcc\": []      # X (feature vectors)\n",
    "    }\n",
    "\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / NUM_SEGMENTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad1acf-13de-47b6-afdc-298b77eea6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# PATH SETTINGS\n",
    "# -----------------------------\n",
    "\n",
    "# Dataset ka folder (GTZAN ka main folder jaha 'blues', 'rock', etc. hain)\n",
    "DATASET_PATH = \"genres_original\"\n",
    "\n",
    "# Features save karne ke liye JSON file ka naam\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "# -----------------------------\n",
    "# AUDIO SETTINGS\n",
    "# -----------------------------\n",
    "\n",
    "SAMPLE_RATE = 22050            # 22.05 kHz pe audio load karenge\n",
    "TRACK_DURATION_SECONDS = 30    # Har track 30 second ka maana hai\n",
    "NUM_SEGMENTS = 10              # 30 sec / 10 = 3 sec per segment\n",
    "\n",
    "# MFCC SETTINGS\n",
    "NUM_MFCC = 13                  # 13 MFCC coefficients\n",
    "N_FFT = 2048                   # FFT window size\n",
    "HOP_LENGTH = 512               # Hop length between frames\n",
    "\n",
    "# 30 sec track me total samples\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION_SECONDS\n",
    "\n",
    "\n",
    "def process_dataset(dataset_path, json_path):\n",
    "    \"\"\"\n",
    "    Pure dataset ko process karke MFCC features + labels\n",
    "    'data.json' me save karega.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ye dictionary final JSON banega\n",
    "    data = {\n",
    "        \"mapping\": [],  # genre index -> genre name (e.g. 0 -> \"blues\")\n",
    "        \"labels\": [],   # y (genre index for each segment)\n",
    "        \"mfcc\": []      # X (MFCC feature vectors)\n",
    "    }\n",
    "\n",
    "    # Har segment me kitne samples honge (3 sec)\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / NUM_SEGMENTS)\n",
    "\n",
    "    # Genre ko number dene ke liye (0,1,2,...)\n",
    "    genre_index = 0\n",
    "\n",
    "    # Har genre folder (e.g. blues, classical, rock, etc.)\n",
    "    for genre_folder in sorted(os.listdir(dataset_path)):\n",
    "        genre_path = os.path.join(dataset_path, genre_folder)\n",
    "\n",
    "        # Sirf folders uthaao (koi file ho to skip)\n",
    "        if not os.path.isdir(genre_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing genre: {genre_folder}\")\n",
    "        data[\"mapping\"].append(genre_folder)  # index -> genre name\n",
    "\n",
    "        # Har audio file (.wav) ke liye\n",
    "        for filename in sorted(os.listdir(genre_path)):\n",
    "            if not filename.endswith(\".wav\"):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(genre_path, filename)\n",
    "            print(f\"  File: {filename}\")\n",
    "\n",
    "            try:\n",
    "                # Audio load karo\n",
    "                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # Sirf un files ko use karo jinki length >= 30 sec hai\n",
    "                if len(signal) >= SAMPLES_PER_TRACK:\n",
    "\n",
    "                    # 10 segments banayenge (3 sec each)\n",
    "                    for s in range(NUM_SEGMENTS):\n",
    "                        start_sample = s * num_samples_per_segment\n",
    "                        end_sample = start_sample + num_samples_per_segment\n",
    "\n",
    "                        # 3-second segment nikaalo\n",
    "                        segment = signal[start_sample:end_sample]\n",
    "\n",
    "                        # -----------------------------\n",
    "                        # MFCC EXTRACT KARNA\n",
    "                        # -----------------------------\n",
    "                        mfccs = librosa.feature.mfcc(\n",
    "                            y=segment,\n",
    "                            sr=sr,\n",
    "                            n_mfcc=NUM_MFCC,\n",
    "                            n_fft=N_FFT,\n",
    "                            hop_length=HOP_LENGTH\n",
    "                        )\n",
    "\n",
    "                        # mfccs shape: (NUM_MFCC, num_frames)\n",
    "                        # Time frames pe mean leke 1D vector banao (13,)\n",
    "                        mfccs_processed = np.mean(mfccs, axis=1)\n",
    "\n",
    "                        # Numpy array -> list (JSON ke liye)\n",
    "                        mfccs_processed = mfccs_processed.tolist()\n",
    "\n",
    "                        # Data dict me store karo\n",
    "                        data[\"mfcc\"].append(mfccs_processed)\n",
    "                        data[\"labels\"].append(genre_index)\n",
    "\n",
    "                else:\n",
    "                    print(f\"  Skipped (too short): {filename}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error loading file {file_path}: {e}\")\n",
    "\n",
    "        # Next genre ke liye index badhao\n",
    "        genre_index += 1\n",
    "\n",
    "    # -----------------------------\n",
    "    # DATA.JSON ME SAVE KARNA\n",
    "    # -----------------------------\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "    print(f\"\\n✅ Saved processed data to {json_path}\")\n",
    "    print(f\"   Total segments: {len(data['mfcc'])}\")\n",
    "    print(f\"   Total labels:   {len(data['labels'])}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562cf22-9224-442d-b8ad-e3f3bc9aaa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python feature_extractor.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6f662-32aa-43d0-9285-f852f068e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Keys:\", data.keys())\n",
    "print(\"Total samples:\", len(data[\"mfcc\"]))\n",
    "print(\"MFCC length:\", len(data[\"mfcc\"][0]))\n",
    "print(\"Chroma length:\", len(data[\"chroma\"][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64560d2-be71-4985-a3f7-1f852c7cfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python feature_extractor.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6390a30-acf1-45f5-b920-fb4405017b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['mapping', 'labels', 'mfcc', 'chroma', 'centroid'])\n",
      "MFCC len: 13\n",
      "Chroma len: 12\n",
      "Centroid len: 1\n",
      "First centroid value: [1773.358004144261]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Keys:\", data.keys())\n",
    "print(\"MFCC len:\", len(data[\"mfcc\"][0]))\n",
    "print(\"Chroma len:\", len(data[\"chroma\"][0]))\n",
    "print(\"Centroid len:\", len(data[\"centroid\"][0]))\n",
    "print(\"First centroid value:\", data[\"centroid\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff21aa-f59f-4074-b7b4-1014687457c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0f23f8-e18c-4c8f-ba24-140ad8b2bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\music-genre-classifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\sahil\\music-genre-classifier\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6c64da-a4d3-413a-a59f-66e2deac756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old data.json deleted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"data.json\"):\n",
    "    os.remove(\"data.json\")\n",
    "    print(\"Old data.json deleted\")\n",
    "else:\n",
    "    print(\"No data.json found to delete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4295817-4b65-4425-8b9d-aa4f4d7ce637",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python feature_extractor.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79296727-94a4-43f2-bad4-b18ec29fc520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f84527-f4cd-4618-8acc-15b08e78ab9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Music Genre Env",
   "language": "python",
   "name": "music-genre-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
